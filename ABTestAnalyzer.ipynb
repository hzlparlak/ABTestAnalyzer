{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Kodun Genel Amacı\n",
        "Bu kod, bir A/B testi (örneğin, bir e-ticaret sitesinde \"Sepete Ekle\" butonunun iki farklı versiyonunun performansını karşılaştırma) için veri analizi yapmak amacıyla yazılmış. İşlevleri:\n",
        "\n",
        "Sentetik veri üretimi: Gerçekçi kullanıcı verileri oluşturur (yaş, cinsiyet, cihaz, dönüşüm, gelir vb.).\n",
        "Veri kalite kontrolü: Verilerde eksiklik, tekrar veya dengesizlik olup olmadığını kontrol eder.\n",
        "İstatistiksel testler: A ve B grupları arasında dönüşüm oranı, sayfa kalış süresi ve gelir farklarını analiz eder.\n",
        "Makine öğrenmesi: Dönüşüm olasılığını tahmin etmek için modeller eğitir.\n",
        "Görselleştirmeler: Test sonuçlarını görselleştirir (örneğin, dönüşüm oranı çubuk grafiği).\n",
        "İş metrikleri: Dönüşüm artışı, kullanıcı başına gelir ve yatırım getirisi (ROI) hesaplar.\n",
        "Unit testler: Kodun doğru çalıştığını doğrulamak için testler içerir.\n",
        "Kod, Google Colab gibi bir ortamda çalıştırılmak üzere tasarlanmış ve sonuçları JSON dosyasına kaydeder, görselleştirmeleri HTML olarak indirir."
      ],
      "metadata": {
        "id": "nFKSkbpzyTM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerekli kütüphaneleri yükler\n",
        "!pip install pandas numpy matplotlib seaborn plotly scikit-learn statsmodels imbalanced-learn\n",
        "!pip install git+https://github.com/Matt52/bayesian-testing.git\n",
        "\n",
        "# Kütüphaneleri içe aktarma: veri işleme, görselleştirme, istatistik ve makine öğrenmesi için\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "import unittest\n",
        "\n",
        "# Uyarı mesajlarını gizleme\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# NumPy veri tiplerini JSON uyumlu Python tiplerine dönüştürme\n",
        "def make_json_serializable(obj):\n",
        "    # NumPy boolean'ı Python boolean'ına çevirme\n",
        "    if isinstance(obj, np.bool_):\n",
        "        return bool(obj)\n",
        "    # NumPy tamsayısını Python tamsayısına çevirme\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    # NumPy ondalık sayısını Python ondalık sayısına çevirme\n",
        "    if isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    # NumPy dizisini Python listesine çevirme\n",
        "    if isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    # Sözlük içindeki değerleri dönüştürme\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: make_json_serializable(v) for k, v in obj.items()}\n",
        "    # Liste içindeki elemanları dönüştürme\n",
        "    if isinstance(obj, list):\n",
        "        return [make_json_serializable(item) for item in obj]\n",
        "    return obj\n",
        "\n",
        "# A/B testi analizini yapan ana sınıf\n",
        "class ABTestAnalyzer:\n",
        "    def __init__(self, config: Optional[Dict] = None):\n",
        "        # Veri ve sonuçlar için boş değişkenler tanımları\n",
        "        self.data = None\n",
        "        self.results = {}\n",
        "        # Kullanıcı yapılandırmasını veya varsayılan ayarları yükleme\n",
        "        self.config = config or self._get_default_config()\n",
        "        # Görselleştirme tarzını ayarlama\n",
        "        plt.style.use('seaborn-v0_8-darkgrid')\n",
        "        sns.set_palette(\"husl\")\n",
        "        print(\" A/B Test Analyzer başlatıldı!\")\n",
        "        print(f\" Konfigürasyon: {len(self.config)} ayar yüklendi\")\n",
        "\n",
        "    # Varsayılan yapılandırma ayarlarını döndürme\n",
        "    def _get_default_config(self) -> Dict:\n",
        "        return {\n",
        "            'alpha_level': 0.05,  # İstatistiksel anlamlılık eşiği (%5)\n",
        "            'power': 0.8,  # Test gücü (%80)\n",
        "            'minimum_effect_size': 0.02,  # Minimum etki büyüklüğü\n",
        "            'confidence_level': 0.95,  # Güven seviyesi (%95)\n",
        "            'random_state': 42,  # Rastgele sayı sabiti\n",
        "            'test_duration_days': 14,  # Test süresi (gün)\n",
        "            'min_sample_size': 1000  # Minimum örnek boyutu\n",
        "        }\n",
        "\n",
        "    # Gerçekçi sentetik veri üretme\n",
        "    def generate_realistic_data(self, n_samples: int = 10000) -> pd.DataFrame:\n",
        "        # Rastgele sayı üretimini sabitleme\n",
        "        np.random.seed(self.config['random_state'])\n",
        "        print(f\"{n_samples:,} kullanıcı için veri oluşturuluyor...\")\n",
        "\n",
        "        # Yaş: Normal dağılımla, 18-70 arası\n",
        "        ages = np.random.normal(35, 12, n_samples)\n",
        "        ages = np.clip(ages, 18, 70).astype(int)\n",
        "        # Cinsiyet: %52 erkek, %48 kadın\n",
        "        genders = np.random.choice(['Male', 'Female'], n_samples, p=[0.52, 0.48])\n",
        "        # Bölge: İstanbul, Ankara vb. farklı olasılıklarla\n",
        "        regions = np.random.choice(\n",
        "            ['Istanbul', 'Ankara', 'Izmir', 'Bursa', 'Antalya', 'Other'],\n",
        "            n_samples, p=[0.35, 0.15, 0.12, 0.08, 0.1, 0.2]\n",
        "        )\n",
        "        # Cihaz: Mobil, masaüstü, tablet\n",
        "        devices = np.random.choice(['mobile', 'desktop', 'tablet'], n_samples, p=[0.65, 0.28, 0.07])\n",
        "        # Grup: A veya B, eşit olasılıkla\n",
        "        groups = np.random.choice(['A', 'B'], n_samples, p=[0.5, 0.5])\n",
        "\n",
        "        # Önceki aktivite puanı: Gamma dağılımı, 0-10 arası\n",
        "        previous_activity = np.random.gamma(2, 2, n_samples)\n",
        "        previous_activity = np.clip(previous_activity, 0, 10)\n",
        "\n",
        "        # Sayfada kalış süresi: Yaş, grup, cihaz ve bölge etkileriyle\n",
        "        base_time = 90 + ages * 0.8 + previous_activity * 8\n",
        "        group_effect = np.where(groups == 'B', 28, 0)  # Grup B için ek süre\n",
        "        device_effect = np.where(devices == 'mobile', -15, np.where(devices == 'tablet', 8, 0))\n",
        "        region_effect = np.where(regions == 'Istanbul', 5, 0)\n",
        "        time_on_page = (base_time + group_effect + device_effect +\n",
        "                       region_effect + np.random.normal(0, 25, n_samples))\n",
        "        time_on_page = np.clip(time_on_page, 15, 500).astype(int)\n",
        "\n",
        "        # Dönüşüm olasılığı: Lojistik modelle hesaplanır\n",
        "        conversion_logit = (\n",
        "            -2.5 + 0.4 * (groups == 'B') + 0.02 * (ages - 35) +\n",
        "            0.3 * (genders == 'Female') + 0.1 * (devices == 'desktop') +\n",
        "            0.05 * previous_activity + 0.002 * time_on_page\n",
        "        )\n",
        "        conversion_prob = 1 / (1 + np.exp(-conversion_logit))\n",
        "        conversions = np.random.binomial(1, conversion_prob, n_samples)\n",
        "\n",
        "        # Gelir: Sadece dönüşüm yapanlar için, log-normal dağılımla\n",
        "        revenue = np.zeros(n_samples)\n",
        "        converted_mask = conversions == 1\n",
        "        n_converted = np.sum(converted_mask)\n",
        "        if n_converted > 0:\n",
        "            base_revenue = np.random.lognormal(4.2, 0.6, n_converted)\n",
        "            group_revenue_multiplier = np.where(groups[converted_mask] == 'B', 1.12, 1.0)\n",
        "            age_effect = 1 + (ages[converted_mask] - 35) * 0.008\n",
        "            revenue[converted_mask] = (base_revenue * group_revenue_multiplier * age_effect)\n",
        "\n",
        "        # Sayfa görüntülemeleri ve tıklamalar: Poisson dağılımı\n",
        "        page_views = np.random.poisson(2.5 + 0.6 * (groups == 'B') + 0.1 * previous_activity, n_samples)\n",
        "        clicks = np.random.poisson(1.8 + 0.4 * (groups == 'B') + 0.08 * previous_activity, n_samples)\n",
        "\n",
        "        # Kayıt tarihleri: Son 14 gün içinde rastgele veya düzenli\n",
        "        start_date = datetime.now() - timedelta(days=self.config['test_duration_days'])\n",
        "        total_minutes = self.config['test_duration_days'] * 24 * 60\n",
        "        if n_samples > total_minutes:\n",
        "            random_minutes = np.random.randint(0, total_minutes, n_samples)\n",
        "            dates = [start_date + timedelta(minutes=int(m)) for m in random_minutes]\n",
        "        else:\n",
        "            freq = total_minutes // n_samples\n",
        "            dates = pd.date_range(start=start_date, periods=n_samples, freq=f'{freq}min')\n",
        "\n",
        "        # Veriyi bir DataFrame'e toplama\n",
        "        self.data = pd.DataFrame({\n",
        "            'user_id': [f'user_{i:06d}' for i in range(1, n_samples + 1)],\n",
        "            'group': groups,\n",
        "            'age': ages,\n",
        "            'gender': genders,\n",
        "            'region': regions,\n",
        "            'device': devices,\n",
        "            'previous_activity_score': np.round(previous_activity, 2),\n",
        "            'time_on_page_seconds': time_on_page,\n",
        "            'page_views': page_views,\n",
        "            'clicks': clicks,\n",
        "            'conversion': conversions,\n",
        "            'revenue_tl': np.round(revenue, 2),\n",
        "            'signup_date': dates,\n",
        "            'day_of_week': [d.day_name() for d in dates],\n",
        "            'hour_of_day': [d.hour for d in dates]\n",
        "        })\n",
        "\n",
        "        # Veri özetini yazdırma\n",
        "        print(f\" Veri oluşturuldu: {len(self.data):,} kayıt\")\n",
        "        print(f\" Grup dağılımı: A={np.sum(groups=='A'):,}, B={np.sum(groups=='B'):,}\")\n",
        "        print(f\" Toplam dönüşüm: {np.sum(conversions):,} ({np.mean(conversions)*100:.1f}%)\")\n",
        "        print(f\" Toplam gelir: {np.sum(revenue):,.0f} TL\")\n",
        "        return self.data\n",
        "\n",
        "    # Verinin kalitesini kontrol etme\n",
        "    def perform_data_quality_checks(self) -> Dict:\n",
        "        # Veri yoksa hata fırlatır\n",
        "        if self.data is None:\n",
        "            raise ValueError(\" Önce veri oluşturun veya yükleyin!\")\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\" VERİ KALİTESİ KONTROLLÜ\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        quality_report = {}\n",
        "        # Eksik verileri kontrol etme\n",
        "        missing_data = self.data.isnull().sum()\n",
        "        quality_report['missing_data'] = missing_data.to_dict()\n",
        "        # Tekrar eden kayıtları kontrol etme\n",
        "        duplicates = self.data.duplicated().sum()\n",
        "        quality_report['duplicates'] = duplicates\n",
        "\n",
        "        # Sayısal sütunlarda aykırı değerleri tespit etme\n",
        "        numeric_cols = self.data.select_dtypes(include=[np.number]).columns\n",
        "        outliers = {}\n",
        "        for col in numeric_cols:\n",
        "            Q1 = self.data[col].quantile(0.25)\n",
        "            Q3 = self.data[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outlier_count = ((self.data[col] < lower_bound) | (self.data[col] > upper_bound)).sum()\n",
        "            outliers[col] = outlier_count\n",
        "        quality_report['outliers'] = outliers\n",
        "\n",
        "        # Grup dengesini kontrol etme\n",
        "        group_balance = self.data['group'].value_counts()\n",
        "        balance_ratio = group_balance.min() / group_balance.max()\n",
        "        quality_report['group_balance'] = {\n",
        "            'counts': group_balance.to_dict(),\n",
        "            'balance_ratio': balance_ratio\n",
        "        }\n",
        "\n",
        "        # Kalite özetini yazdırma\n",
        "        print(f\" Toplam kayıt sayısı: {len(self.data):,}\")\n",
        "        print(f\" Eksik veri: {missing_data.sum()} adet\")\n",
        "        print(f\" Duplicate kayıt: {duplicates} adet\")\n",
        "        print(f\" Grup dengesi oranı: {balance_ratio:.3f}\")\n",
        "        if missing_data.sum() == 0:\n",
        "            print(\" Eksik veri yok!\")\n",
        "        if duplicates == 0:\n",
        "            print(\" Duplicate kayıt yok!\")\n",
        "        if balance_ratio > 0.95:\n",
        "            print(\" Grup dağılımı dengeli!\")\n",
        "        return quality_report\n",
        "\n",
        "    # İstatistiksel testler\n",
        "    def run_statistical_tests(self) -> Dict:\n",
        "        # Veri yoksa hata fırlatma\n",
        "        if self.data is None:\n",
        "            raise ValueError(\" Önce veri oluşturun!\")\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\" İSTATİSTİKSEL TESTLER\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        test_results = {}\n",
        "        group_a = self.data[self.data['group'] == 'A']\n",
        "        group_b = self.data[self.data['group'] == 'B']\n",
        "\n",
        "        # 1. Dönüşüm oranı analizi (Chi-square testi)\n",
        "        print(\"\\n 1 DÖNÜŞÜM ORANI ANALİZİ\")\n",
        "        print(\"-\" * 30)\n",
        "        contingency_table = pd.crosstab(self.data['group'], self.data['conversion'])\n",
        "        chi2, p_chi2, dof, expected = chi2_contingency(contingency_table)\n",
        "        conv_rate_a = group_a['conversion'].mean()\n",
        "        conv_rate_b = group_b['conversion'].mean()\n",
        "        relative_lift = ((conv_rate_b - conv_rate_a) / conv_rate_a) * 100\n",
        "        test_results['conversion_analysis'] = {\n",
        "            'chi2_statistic': float(chi2),\n",
        "            'p_value': float(p_chi2),\n",
        "            'degrees_of_freedom': int(dof),\n",
        "            'conversion_rate_a': float(conv_rate_a),\n",
        "            'conversion_rate_b': float(conv_rate_b),\n",
        "            'absolute_lift': float(conv_rate_b - conv_rate_a),\n",
        "            'relative_lift_percent': float(relative_lift),\n",
        "            'is_significant': int(p_chi2 < self.config['alpha_level'])\n",
        "        }\n",
        "        print(f\"   Grup A Dönüşüm Oranı: {conv_rate_a:.4f} ({conv_rate_a*100:.2f}%)\")\n",
        "        print(f\"   Grup B Dönüşüm Oranı: {conv_rate_b:.4f} ({conv_rate_b*100:.2f}%)\")\n",
        "        print(f\"   Relatif İyileştirme: {relative_lift:+.2f}%\")\n",
        "        print(f\"   Chi-square: {chi2:.4f}, p-value: {p_chi2:.6f}\")\n",
        "        print(f\"   Sonuç: {' İstatistiksel olarak anlamlı' if p_chi2 < 0.05 else ' Anlamlı değil'}\")\n",
        "\n",
        "        # 2. Sayfa kalış süresi analizi (T-test)\n",
        "        print(\"\\n 2 SAYFA KALIŞ SÜRESİ ANALİZİ\")\n",
        "        print(\"-\" * 30)\n",
        "        t_stat, p_ttest = ttest_ind(group_a['time_on_page_seconds'], group_b['time_on_page_seconds'], equal_var=False)\n",
        "        levene_stat, levene_p = stats.levene(group_a['time_on_page_seconds'], group_b['time_on_page_seconds'])\n",
        "        pooled_std = np.sqrt(((len(group_a)-1)*group_a['time_on_page_seconds'].var() +\n",
        "                             (len(group_b)-1)*group_b['time_on_page_seconds'].var()) /\n",
        "                            (len(group_a)+len(group_b)-2))\n",
        "        cohens_d = (group_b['time_on_page_seconds'].mean() - group_a['time_on_page_seconds'].mean()) / pooled_std\n",
        "        test_results['time_on_page_analysis'] = {\n",
        "            't_statistic': float(t_stat),\n",
        "            'p_value': float(p_ttest),\n",
        "            'levene_p_value': float(levene_p),\n",
        "            'cohens_d': float(cohens_d),\n",
        "            'mean_a': float(group_a['time_on_page_seconds'].mean()),\n",
        "            'mean_b': float(group_b['time_on_page_seconds'].mean()),\n",
        "            'is_significant': int(p_ttest < self.config['alpha_level'])\n",
        "        }\n",
        "        print(f\"   Grup A Ortalama: {group_a['time_on_page_seconds'].mean():.1f} saniye\")\n",
        "        print(f\"   Grup B Ortalama: {group_b['time_on_page_seconds'].mean():.1f} saniye\")\n",
        "        print(f\"   T-test: t={t_stat:.4f}, p-value={p_ttest:.6f}\")\n",
        "        print(f\"   Cohen's d: {cohens_d:.3f}\")\n",
        "        print(f\"   Sonuç: {' İstatistiksel olarak anlamlı' if p_ttest < 0.05 else ' Anlamlı değil'}\")\n",
        "\n",
        "        # 3. Gelir analizi (Mann-Whitney U testi)\n",
        "        print(\"\\n 3 GELİR ANALİZİ\")\n",
        "        print(\"-\" * 30)\n",
        "        mw_stat, p_mw = mannwhitneyu(group_a['revenue_tl'], group_b['revenue_tl'], alternative='two-sided')\n",
        "        test_results['revenue_analysis'] = {\n",
        "            'mw_statistic': float(mw_stat),\n",
        "            'p_value': float(p_mw),\n",
        "            'median_a': float(group_a['revenue_tl'].median()),\n",
        "            'median_b': float(group_b['revenue_tl'].median()),\n",
        "            'is_significant': int(p_mw < self.config['alpha_level'])\n",
        "        }\n",
        "        print(f\"   Grup A Medyan Gelir: {group_a['revenue_tl'].median():.2f} TL\")\n",
        "        print(f\"   Grup B Medyan Gelir: {group_b['revenue_tl'].median():.2f} TL\")\n",
        "        print(f\"   Mann-Whitney U: stat={mw_stat:.4f}, p-value={p_mw:.6f}\")\n",
        "        print(f\"   Sonuç: {' İstatistiksel olarak anlamlı' if p_mw < 0.05 else ' Anlamlı değil'}\")\n",
        "\n",
        "        # 4. Bayesçi A/B testi\n",
        "        print(\"\\n 4 BAYESÇİ A/B TESTİ\")\n",
        "        print(\"-\" * 30)\n",
        "        try:\n",
        "            from scipy.stats import beta\n",
        "            a_A, b_A = group_a['conversion'].sum() + 1, len(group_a) - group_a['conversion'].sum() + 1\n",
        "            a_B, b_B = group_b['conversion'].sum() + 1, len(group_b) - group_b['conversion'].sum() + 1\n",
        "            beta_A = beta.rvs(a_A, b_A, size=10000)\n",
        "            beta_B = beta.rvs(a_B, b_B, size=10000)\n",
        "            prob_B_better = np.mean(beta_B > beta_A)\n",
        "            test_results['bayesian_analysis'] = {\n",
        "                'probability_B_better': float(prob_B_better),\n",
        "                'mean_conversion_A': float(a_A / (a_A + b_A)),\n",
        "                'mean_conversion_B': float(a_B / (a_B + b_B))\n",
        "            }\n",
        "            print(f\"   Grup B'nin daha iyi olma olasılığı: {prob_B_better:.3f}\")\n",
        "            print(f\"   Ortalama Dönüşüm (A): {a_A / (a_A + b_A):.4f}\")\n",
        "            print(f\"   Ortalama Dönüşüm (B): {a_B / (a_B + b_B):.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   Bayesçi test hatası: {str(e)}\")\n",
        "            test_results['bayesian_analysis'] = {'error': str(e)}\n",
        "\n",
        "        # 5. Güç analizi\n",
        "        print(\"\\n 5 GÜÇ ANALİZİ\")\n",
        "        print(\"-\" * 30)\n",
        "        power_analysis = TTestIndPower()\n",
        "        effect_size = abs(conv_rate_b - conv_rate_a) / np.sqrt((conv_rate_a * (1 - conv_rate_a) + conv_rate_b * (1 - conv_rate_b)) / 2)\n",
        "        power = power_analysis.solve_power(effect_size=effect_size, nobs1=len(group_a), alpha=self.config['alpha_level'])\n",
        "        test_results['power_analysis'] = {\n",
        "            'effect_size': float(effect_size),\n",
        "            'power': float(power),\n",
        "            'sample_size_per_group': int(len(group_a))\n",
        "        }\n",
        "        print(f\"   Etki Büyüklüğü: {effect_size:.3f}\")\n",
        "        print(f\"   Test Gücü: {power:.3f} (>{self.config['power']} idealdir)\")\n",
        "\n",
        "        self.results['statistical_tests'] = test_results\n",
        "        return test_results\n",
        "\n",
        "    # Makine öğrenmesi modellerini eğitme\n",
        "    def train_ml_models(self) -> Dict:\n",
        "        # Veri yoksa hata fırlatma\n",
        "        if self.data is None:\n",
        "            raise ValueError(\" Önce veri oluşturun!\")\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\" MAKİNE ÖĞRENMESİ MODELLERİ\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Özellikleri seçme (interaction_score hariç, sonradan oluşturulacak)\n",
        "        features = ['age', 'gender', 'region', 'device', 'previous_activity_score',\n",
        "                    'time_on_page_seconds', 'page_views', 'clicks']\n",
        "        X = self.data[features].copy()\n",
        "        # Sayfada kalış süresini log dönüşümü uygulama\n",
        "        X['time_on_page_seconds'] = np.log1p(X['time_on_page_seconds'])\n",
        "        # Yeni özellik: interaction_score = sayfa görüntülemeleri * tıklamalar\n",
        "        X['interaction_score'] = X['page_views'] * X['clicks']\n",
        "\n",
        "        # Hedef değişken: dönüşüm\n",
        "        target = 'conversion'\n",
        "        y = self.data[target]\n",
        "\n",
        "        # Kategorik değişkenleri sayısal değerlere dönüştürme\n",
        "        le = LabelEncoder()\n",
        "        for col in ['gender', 'region', 'device']:\n",
        "            X[col] = le.fit_transform(X[col])\n",
        "\n",
        "        # Veriyi eğitim ve test setlerine böler (%80 eğitim, %20 test)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=self.config['random_state'], stratify=y\n",
        "        )\n",
        "\n",
        "        # Özellikleri standartlaştırma\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Dengesiz sınıfları dengelemek için SMOTE uygulama\n",
        "        smote = SMOTE(random_state=self.config['random_state'])\n",
        "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "        # Modelleri tanımlama\n",
        "        models = {\n",
        "            'Logistic Regression': LogisticRegression(random_state=self.config['random_state'], class_weight='balanced'),\n",
        "            'Random Forest': RandomForestClassifier(\n",
        "                random_state=self.config['random_state'], n_estimators=200, max_depth=5, min_samples_split=5\n",
        "            ),\n",
        "            'Gradient Boosting': GradientBoostingClassifier(\n",
        "                random_state=self.config['random_state'], n_estimators=200, max_depth=5, learning_rate=0.05\n",
        "            )\n",
        "        }\n",
        "\n",
        "        model_results = {}\n",
        "        # Her modeli eğitme ve değerlendirme\n",
        "        for name, model in models.items():\n",
        "            print(f\"\\n {name} modeli eğitiliyor...\")\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_prob = model.predict_proba(X_test)[:, 1]\n",
        "            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "            auc = roc_auc_score(y_test, y_prob)\n",
        "            model_results[name] = {\n",
        "                'classification_report': report,\n",
        "                'roc_auc': float(auc),\n",
        "                'confusion_matrix': confusion_matrix(y_test, y_pred).tolist()\n",
        "            }\n",
        "            print(f\"   ROC AUC: {auc:.3f}\")\n",
        "            print(f\"   Precision (1): {report['1']['precision']:.3f}\")\n",
        "            print(f\"   Recall (1): {report['1']['recall']:.3f}\")\n",
        "\n",
        "        self.results['ml_models'] = model_results\n",
        "        return model_results\n",
        "\n",
        "    # Görselleştirmeler  ve HTML dosyalarını kaydedetme\n",
        "    def create_visualizations(self, output_dir: str = 'results/') -> None:\n",
        "        # Veri yoksa hata fırlatır\n",
        "        if self.data is None:\n",
        "            raise ValueError(\" Önce veri oluşturun!\")\n",
        "        # Çıktı dizini yoksa oluşturma\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\" GÖRSELLEŞTİRMELER\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Dönüşüm oranı çubuk grafiği\n",
        "        conv_rates = self.data.groupby('group')['conversion'].mean()\n",
        "        fig = px.bar(\n",
        "            x=conv_rates.index,\n",
        "            y=conv_rates.values,\n",
        "            title='A/B Testi: Dönüşüm Oranı Karşılaştırması',\n",
        "            labels={'x': 'Grup', 'y': 'Dönüşüm Oranı'},\n",
        "            color=conv_rates.index,\n",
        "            text=[f\"{x:.2%}\" for x in conv_rates.values]\n",
        "        )\n",
        "        fig.update_layout(showlegend=False)\n",
        "        fig.update_yaxes(range=[0, max(conv_rates.values) + 0.05])\n",
        "        fig.update_traces(textposition='auto')\n",
        "        fig.write_html(os.path.join(output_dir, 'conversion_rates.html'))\n",
        "        print(f\" Dönüşüm oranı grafiği kaydedildi: {output_dir}conversion_rates.html\")\n",
        "\n",
        "        # Cihaz türüne göre segmentasyon grafiği\n",
        "        segment_data = self.data.groupby(['group', 'device'])['conversion'].mean().unstack()\n",
        "        fig = go.Figure(data=[\n",
        "            go.Bar(name=device, x=segment_data.index, y=segment_data[device])\n",
        "            for device in segment_data.columns\n",
        "        ])\n",
        "        fig.update_layout(\n",
        "            title='Cihaz Türüne Göre Dönüşüm Oranları',\n",
        "            xaxis_title='Grup',\n",
        "            yaxis_title='Dönüşüm Oranı',\n",
        "            barmode='group'\n",
        "        )\n",
        "        fig.write_html(os.path.join(output_dir, 'device_segmentation.html'))\n",
        "        print(f\" Segmentasyon grafiği kaydedildi: {output_dir}device_segmentation.html\")\n",
        "\n",
        "        # Gelir dağılımı kutu grafiği\n",
        "        fig = px.box(\n",
        "            self.data[self.data['revenue_tl'] > 0],\n",
        "            x='group',\n",
        "            y='revenue_tl',\n",
        "            title='Grup Bazında Gelir Dağılımı (Dönüşen Kullanıcılar)',\n",
        "            color='group'\n",
        "        )\n",
        "        fig.update_layout(yaxis_title='Gelir (TL)')\n",
        "        fig.write_html(os.path.join(output_dir, 'revenue_distribution.html'))\n",
        "        print(f\" Gelir dağılımı grafiği kaydedildi: {output_dir}revenue_distribution.html\")\n",
        "\n",
        "    # İş metriklerini hesaplama\n",
        "    def calculate_business_metrics(self) -> Dict:\n",
        "        # Veri yoksa hata fırlatma\n",
        "        if self.data is None:\n",
        "            raise ValueError(\" Önce veri oluşturun!\")\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\" İŞ METRİKLERİ\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        metrics = {}\n",
        "        group_a = self.data[self.data['group'] == 'A']\n",
        "        group_b = self.data[self.data['group'] == 'B']\n",
        "        # Dönüşüm oranı artışı\n",
        "        conv_rate_a = group_a['conversion'].mean()\n",
        "        conv_rate_b = group_b['conversion'].mean()\n",
        "        lift = (conv_rate_b - conv_rate_a) / conv_rate_a * 100\n",
        "        # Kullanıcı başına gelir\n",
        "        rpu_a = group_a['revenue_tl'].mean()\n",
        "        rpu_b = group_b['revenue_tl'].mean()\n",
        "        rpu_lift = (rpu_b - rpu_a) / rpu_a * 100\n",
        "        # Yatırım getirisi (ROI)\n",
        "        test_cost = 5000\n",
        "        expected_revenue_b = rpu_b * len(group_b)\n",
        "        roi = ((expected_revenue_b - test_cost) / test_cost) * 100\n",
        "        metrics = {\n",
        "            'conversion_lift_percent': float(lift),\n",
        "            'revenue_per_user_a': float(rpu_a),\n",
        "            'revenue_per_user_b': float(rpu_b),\n",
        "            'revenue_lift_percent': float(rpu_lift),\n",
        "            'estimated_roi_percent': float(roi)\n",
        "        }\n",
        "        print(f\"   Dönüşüm Artışı: {lift:.2f}%\")\n",
        "        print(f\"   Kullanıcı Başına Gelir (A): {rpu_a:.2f} TL\")\n",
        "        print(f\"   Kullanıcı Başına Gelir (B): {rpu_b:.2f} TL\")\n",
        "        print(f\"   Gelir Artışı: {rpu_lift:.2f}%\")\n",
        "        print(f\"   Tahmini ROI: {roi:.2f}%\")\n",
        "        self.results['business_metrics'] = metrics\n",
        "        return metrics\n",
        "\n",
        "    # Tüm analiz adımlarını çalıştırma\n",
        "    def run_complete_analysis(self, output_dir: str = 'results/') -> Dict:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\" TAM ANALİZ BAŞLIYOR\")\n",
        "        print(\"=\"*50)\n",
        "        # Veri yoksa üretme\n",
        "        if self.data is None:\n",
        "            self.generate_realistic_data()\n",
        "        # Kalite kontrolü\n",
        "        self.perform_data_quality_checks()\n",
        "        # İstatistiksel testleri çalıştırma\n",
        "        self.run_statistical_tests()\n",
        "        # Makine öğrenmesi modellerini eğitme\n",
        "        self.train_ml_models()\n",
        "        # Görselleştirmeler oluşturma\n",
        "        self.create_visualizations(output_dir)\n",
        "        # İş metriklerini hesaplar\n",
        "        self.calculate_business_metrics()\n",
        "        # Sonuçları JSON formatına çevirir ve kaydeder\n",
        "        serializable_results = make_json_serializable(self.results)\n",
        "        with open(os.path.join(output_dir, 'results.json'), 'w') as f:\n",
        "            json.dump(serializable_results, f, indent=4)\n",
        "        print(f\" Sonuçlar kaydedildi: {output_dir}results.json\")\n",
        "        return self.results\n",
        "\n",
        "    # Sonuçları JSON dosyasına kaydeder\n",
        "    def save_results(self, output_dir: str = 'results/') -> None:\n",
        "        # Çıktı dizini yoksa oluşturur\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "        # Sonuçları JSON uyumlu hale getirir\n",
        "        serializable_results = make_json_serializable(self.results)\n",
        "        with open(os.path.join(output_dir, 'results.json'), 'w') as f:\n",
        "            json.dump(serializable_results, f, indent=4)\n",
        "        print(f\" Sonuçlar kaydedildi: {output_dir}results.json\")\n",
        "\n",
        "# Unit testler: Kodun doğruluğunu kontrol eder\n",
        "class TestDataGenerator(unittest.TestCase):\n",
        "    # Veri üretimini test eder\n",
        "    def test_data_generation(self):\n",
        "        analyzer = ABTestAnalyzer()\n",
        "        data = analyzer.generate_realistic_data(n_samples=100)\n",
        "        self.assertEqual(len(data), 100)\n",
        "        self.assertIn('conversion', data.columns)\n",
        "        self.assertIn('signup_date', data.columns)\n",
        "        self.assertIn('group', data.columns)\n",
        "        self.assertTrue(all(data['group'].isin(['A', 'B'])))\n",
        "        self.assertGreater(data['conversion'].mean(), 0)\n",
        "\n",
        "    # Grup dengesini test eder\n",
        "    def test_group_balance(self):\n",
        "        analyzer = ABTestAnalyzer()\n",
        "        data = analyzer.generate_realistic_data(n_samples=100)\n",
        "        group_counts = data['group'].value_counts()\n",
        "        balance_ratio = group_counts.min() / group_counts.max()\n",
        "        self.assertGreater(balance_ratio, 0.8)  # Grup dengesi %80'den fazla\n",
        "\n",
        "    # Dönüşüm oranı artışını test eder\n",
        "    def test_conversion_lift(self):\n",
        "        analyzer = ABTestAnalyzer()\n",
        "        data = analyzer.generate_realistic_data(n_samples=100)\n",
        "        conv_rate_a = data[data['group'] == 'A']['conversion'].mean()\n",
        "        conv_rate_b = data[data['group'] == 'B']['conversion'].mean()\n",
        "        self.assertGreater(conv_rate_b, conv_rate_a)  # Grup B daha yüksek dönüşüm\n",
        "\n",
        "    # Veri kalitesini test eder\n",
        "    def test_data_quality(self):\n",
        "        analyzer = ABTestAnalyzer()\n",
        "        data = analyzer.generate_realistic_data(n_samples=100)\n",
        "        self.assertEqual(data.isnull().sum().sum(), 0)  # Eksik veri yok\n",
        "        self.assertEqual(data.duplicated().sum(), 0)   # Tekrar eden kayıt yok\n",
        "\n",
        "    # Gelir dağılımını test eder\n",
        "    def test_revenue_distribution(self):\n",
        "        analyzer = ABTestAnalyzer()\n",
        "        data = analyzer.generate_realistic_data(n_samples=100)\n",
        "        revenue_converted = data[data['conversion'] == 1]['revenue_tl']\n",
        "        self.assertGreater(revenue_converted.mean(), 0)  # Dönüşenlerin geliri pozitif\n",
        "\n",
        "    # Makine öğrenmesi performansını test eder\n",
        "    def test_ml_performance(self):\n",
        "        analyzer = ABTestAnalyzer()\n",
        "        data = analyzer.generate_realistic_data(n_samples=1000)\n",
        "        results = analyzer.train_ml_models()\n",
        "        for model_name, metrics in results.items():\n",
        "            self.assertGreater(metrics['roc_auc'], 0.5)  # ROC AUC > 0.5\n",
        "\n",
        "# Testleri ve tam analizi çalıştırır\n",
        "try:\n",
        "    # Unit testleri çalıştırır\n",
        "    print(\"\\n Unit Testler Çalıştırılıyor...\")\n",
        "    unittest.main(argv=[''], exit=False)\n",
        "\n",
        "    # Tam analizi başlatır\n",
        "    analyzer = ABTestAnalyzer()\n",
        "    results = analyzer.run_complete_analysis()\n",
        "\n",
        "    # Sonuçları JSON dosyasından okur ve yazdırır\n",
        "    print(\"\\n Sonuçlar:\")\n",
        "    with open('results/results.json', 'r') as f:\n",
        "        print(json.load(f))\n",
        "\n",
        "    # Görselleştirme dosyalarını indirir (Google Colab için)\n",
        "    from google.colab import files\n",
        "    for file in ['conversion_rates.html', 'device_segmentation.html', 'revenue_distribution.html']:\n",
        "        file_path = os.path.join('results', file)\n",
        "        if os.path.exists(file_path):\n",
        "            files.download(file_path)\n",
        "            print(f\" {file} indirildi\")\n",
        "        else:\n",
        "            print(f\"Uyarı: {file} bulunamadı!\")\n",
        "except Exception as e:\n",
        "    # Hata olursa mesajı ve ayrıntıları yazdırır\n",
        "    print(f\"Hata oluştu: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mWhwn4SF3GdU",
        "outputId": "0d315b48-bc2e-4686-8417-33c2bf674e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting git+https://github.com/Matt52/bayesian-testing.git\n",
            "  Cloning https://github.com/Matt52/bayesian-testing.git to /tmp/pip-req-build-2c_wxnbl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Matt52/bayesian-testing.git /tmp/pip-req-build-2c_wxnbl\n",
            "  Resolved https://github.com/Matt52/bayesian-testing.git to commit cea9afa5d7e3321d159d7b387ff57803467a18d5\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from bayesian-testing==0.9.1) (2.0.2)\n",
            "Building wheels for collected packages: bayesian-testing\n",
            "  Building wheel for bayesian-testing (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-testing: filename=bayesian_testing-0.9.1-py3-none-any.whl size=33344 sha256=602e99a3783b7abebea44cbeff0d8cd22388bdddfbe0cf675b3a83df5bd9d3ce\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0zp8x9qw/wheels/87/c4/b3/03ee000efc07699d97e6d89880515babe51416b41b59eec945\n",
            "Successfully built bayesian-testing\n",
            "Installing collected packages: bayesian-testing\n",
            "Successfully installed bayesian-testing-0.9.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "...."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Unit Testler Çalıştırılıyor...\n",
            " A/B Test Analyzer başlatıldı!\n",
            " Konfigürasyon: 7 ayar yüklendi\n",
            "100 kullanıcı için veri oluşturuluyor...\n",
            " Veri oluşturuldu: 100 kayıt\n",
            " Grup dağılımı: A=45, B=55\n",
            " Toplam dönüşüm: 14 (14.0%)\n",
            " Toplam gelir: 1,074 TL\n",
            " A/B Test Analyzer başlatıldı!\n",
            " Konfigürasyon: 7 ayar yüklendi\n",
            "100 kullanıcı için veri oluşturuluyor...\n",
            " Veri oluşturuldu: 100 kayıt\n",
            " Grup dağılımı: A=45, B=55\n",
            " Toplam dönüşüm: 14 (14.0%)\n",
            " Toplam gelir: 1,074 TL\n",
            " A/B Test Analyzer başlatıldı!\n",
            " Konfigürasyon: 7 ayar yüklendi\n",
            "100 kullanıcı için veri oluşturuluyor...\n",
            " Veri oluşturuldu: 100 kayıt\n",
            " Grup dağılımı: A=45, B=55\n",
            " Toplam dönüşüm: 14 (14.0%)\n",
            " Toplam gelir: 1,074 TL\n",
            " A/B Test Analyzer başlatıldı!\n",
            " Konfigürasyon: 7 ayar yüklendi\n",
            "100 kullanıcı için veri oluşturuluyor...\n",
            " Veri oluşturuldu: 100 kayıt\n",
            " Grup dağılımı: A=45, B=55\n",
            " Toplam dönüşüm: 14 (14.0%)\n",
            " Toplam gelir: 1,074 TL\n",
            " A/B Test Analyzer başlatıldı!\n",
            " Konfigürasyon: 7 ayar yüklendi\n",
            "1,000 kullanıcı için veri oluşturuluyor...\n",
            " Veri oluşturuldu: 1,000 kayıt\n",
            " Grup dağılımı: A=511, B=489\n",
            " Toplam dönüşüm: 158 (15.8%)\n",
            " Toplam gelir: 14,456 TL\n",
            "\n",
            "==================================================\n",
            " MAKİNE ÖĞRENMESİ MODELLERİ\n",
            "==================================================\n",
            "\n",
            " Logistic Regression modeli eğitiliyor...\n",
            "   ROC AUC: 0.617\n",
            "   Precision (1): 0.195\n",
            "   Recall (1): 0.469\n",
            "\n",
            " Random Forest modeli eğitiliyor...\n",
            "   ROC AUC: 0.461\n",
            "   Precision (1): 0.118\n",
            "   Recall (1): 0.250\n",
            "\n",
            " Gradient Boosting modeli eğitiliyor...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "F.\n",
            "======================================================================\n",
            "FAIL: test_ml_performance (__main__.TestDataGenerator.test_ml_performance)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-1-143310588>\", line 592, in test_ml_performance\n",
            "    self.assertGreater(metrics['roc_auc'], 0.5)  # ROC AUC > 0.5\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: 0.46130952380952384 not greater than 0.5\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 6 tests in 2.446s\n",
            "\n",
            "FAILED (failures=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ROC AUC: 0.471\n",
            "   Precision (1): 0.000\n",
            "   Recall (1): 0.000\n",
            " A/B Test Analyzer başlatıldı!\n",
            " Konfigürasyon: 7 ayar yüklendi\n",
            "100 kullanıcı için veri oluşturuluyor...\n",
            " Veri oluşturuldu: 100 kayıt\n",
            " Grup dağılımı: A=45, B=55\n",
            " Toplam dönüşüm: 14 (14.0%)\n",
            " Toplam gelir: 1,074 TL\n",
            " A/B Test Analyzer başlatıldı!\n",
            " Konfigürasyon: 7 ayar yüklendi\n",
            "\n",
            "==================================================\n",
            " TAM ANALİZ BAŞLIYOR\n",
            "==================================================\n",
            "10,000 kullanıcı için veri oluşturuluyor...\n",
            " Veri oluşturuldu: 10,000 kayıt\n",
            " Grup dağılımı: A=5,022, B=4,978\n",
            " Toplam dönüşüm: 1,661 (16.6%)\n",
            " Toplam gelir: 144,145 TL\n",
            "\n",
            "==================================================\n",
            " VERİ KALİTESİ KONTROLLÜ\n",
            "==================================================\n",
            " Toplam kayıt sayısı: 10,000\n",
            " Eksik veri: 0 adet\n",
            " Duplicate kayıt: 0 adet\n",
            " Grup dengesi oranı: 0.991\n",
            " Eksik veri yok!\n",
            " Duplicate kayıt yok!\n",
            " Grup dağılımı dengeli!\n",
            "\n",
            "==================================================\n",
            " İSTATİSTİKSEL TESTLER\n",
            "==================================================\n",
            "\n",
            " 1 DÖNÜŞÜM ORANI ANALİZİ\n",
            "------------------------------\n",
            "   Grup A Dönüşüm Oranı: 0.1438 (14.38%)\n",
            "   Grup B Dönüşüm Oranı: 0.1886 (18.86%)\n",
            "   Relatif İyileştirme: +31.20%\n",
            "   Chi-square: 36.0027, p-value: 0.000000\n",
            "   Sonuç:  İstatistiksel olarak anlamlı\n",
            "\n",
            " 2 SAYFA KALIŞ SÜRESİ ANALİZİ\n",
            "------------------------------\n",
            "   Grup A Ortalama: 142.0 saniye\n",
            "   Grup B Ortalama: 170.0 saniye\n",
            "   T-test: t=-40.8317, p-value=0.000000\n",
            "   Cohen's d: 0.817\n",
            "   Sonuç:  İstatistiksel olarak anlamlı\n",
            "\n",
            " 3 GELİR ANALİZİ\n",
            "------------------------------\n",
            "   Grup A Medyan Gelir: 0.00 TL\n",
            "   Grup B Medyan Gelir: 0.00 TL\n",
            "   Mann-Whitney U: stat=11909912.5000, p-value=0.000000\n",
            "   Sonuç:  İstatistiksel olarak anlamlı\n",
            "\n",
            " 4 BAYESÇİ A/B TESTİ\n",
            "------------------------------\n",
            "   Grup B'nin daha iyi olma olasılığı: 1.000\n",
            "   Ortalama Dönüşüm (A): 0.1439\n",
            "   Ortalama Dönüşüm (B): 0.1888\n",
            "\n",
            " 5 GÜÇ ANALİZİ\n",
            "------------------------------\n",
            "   Etki Büyüklüğü: 0.121\n",
            "   Test Gücü: 1.000 (>0.8 idealdir)\n",
            "\n",
            "==================================================\n",
            " MAKİNE ÖĞRENMESİ MODELLERİ\n",
            "==================================================\n",
            "\n",
            " Logistic Regression modeli eğitiliyor...\n",
            "   ROC AUC: 0.590\n",
            "   Precision (1): 0.203\n",
            "   Recall (1): 0.578\n",
            "\n",
            " Random Forest modeli eğitiliyor...\n",
            "   ROC AUC: 0.574\n",
            "   Precision (1): 0.207\n",
            "   Recall (1): 0.479\n",
            "\n",
            " Gradient Boosting modeli eğitiliyor...\n",
            "   ROC AUC: 0.549\n",
            "   Precision (1): 0.312\n",
            "   Recall (1): 0.015\n",
            "\n",
            "==================================================\n",
            " GÖRSELLEŞTİRMELER\n",
            "==================================================\n",
            " Dönüşüm oranı grafiği kaydedildi: results/conversion_rates.html\n",
            " Segmentasyon grafiği kaydedildi: results/device_segmentation.html\n",
            " Gelir dağılımı grafiği kaydedildi: results/revenue_distribution.html\n",
            "\n",
            "==================================================\n",
            " İŞ METRİKLERİ\n",
            "==================================================\n",
            "   Dönüşüm Artışı: 31.20%\n",
            "   Kullanıcı Başına Gelir (A): 11.74 TL\n",
            "   Kullanıcı Başına Gelir (B): 17.12 TL\n",
            "   Gelir Artışı: 45.82%\n",
            "   Tahmini ROI: 1603.99%\n",
            " Sonuçlar kaydedildi: results/results.json\n",
            "\n",
            " Sonuçlar:\n",
            "{'statistical_tests': {'conversion_analysis': {'chi2_statistic': 36.00268755050091, 'p_value': 1.9704556282393473e-09, 'degrees_of_freedom': 1, 'conversion_rate_a': 0.14376742333731582, 'conversion_rate_b': 0.18862997187625552, 'absolute_lift': 0.0448625485389397, 'relative_lift_percent': 31.204947197029803, 'is_significant': 1}, 'time_on_page_analysis': {'t_statistic': -40.83166041590437, 'p_value': 0.0, 'levene_p_value': 0.33164935633376746, 'cohens_d': 0.8165968028935049, 'mean_a': 142.03405017921148, 'mean_b': 170.0034150261149, 'is_significant': 1}, 'revenue_analysis': {'mw_statistic': 11909912.5, 'p_value': 2.889550768596512e-10, 'median_a': 0.0, 'median_b': 0.0, 'is_significant': 1}, 'bayesian_analysis': {'probability_B_better': 1.0, 'mean_conversion_A': 0.1439092356687898, 'mean_conversion_B': 0.18875502008032127}, 'power_analysis': {'effect_size': 0.12073376097815697, 'power': 0.9999783765514573, 'sample_size_per_group': 5022}}, 'ml_models': {'Logistic Regression': {'classification_report': {'0': {'precision': 0.8669201520912547, 'recall': 0.5467625899280576, 'f1-score': 0.6705882352941176, 'support': 1668.0}, '1': {'precision': 0.20253164556962025, 'recall': 0.5783132530120482, 'f1-score': 0.3, 'support': 332.0}, 'accuracy': 0.552, 'macro avg': {'precision': 0.5347258988304375, 'recall': 0.5625379214700529, 'f1-score': 0.48529411764705876, 'support': 2000.0}, 'weighted avg': {'precision': 0.7566316600086634, 'recall': 0.552, 'f1-score': 0.609070588235294, 'support': 2000.0}}, 'roc_auc': 0.5897312270665396, 'confusion_matrix': [[912, 756], [140, 192]]}, 'Random Forest': {'classification_report': {'0': {'precision': 0.859463850528026, 'recall': 0.6342925659472423, 'f1-score': 0.7299068644360124, 'support': 1668.0}, '1': {'precision': 0.2067620286085826, 'recall': 0.4789156626506024, 'f1-score': 0.2888283378746594, 'support': 332.0}, 'accuracy': 0.6085, 'macro avg': {'precision': 0.5331129395683043, 'recall': 0.5566041142989223, 'f1-score': 0.5093676011553359, 'support': 2000.0}, 'weighted avg': {'precision': 0.7511153480893984, 'recall': 0.6085, 'f1-score': 0.6566878290268278, 'support': 2000.0}}, 'roc_auc': 0.5735342448932421, 'confusion_matrix': [[1058, 610], [173, 159]]}, 'Gradient Boosting': {'classification_report': {'0': {'precision': 0.8351814516129032, 'recall': 0.9934052757793765, 'f1-score': 0.907447973713034, 'support': 1668.0}, '1': {'precision': 0.3125, 'recall': 0.015060240963855422, 'f1-score': 0.028735632183908046, 'support': 332.0}, 'accuracy': 0.831, 'macro avg': {'precision': 0.5738407258064516, 'recall': 0.504232758371616, 'f1-score': 0.468091802948471, 'support': 2000.0}, 'weighted avg': {'precision': 0.7484163306451613, 'recall': 0.831, 'f1-score': 0.7615817250191991, 'support': 2000.0}}, 'roc_auc': 0.5489313368582243, 'confusion_matrix': [[1657, 11], [327, 5]]}}, 'business_metrics': {'conversion_lift_percent': 31.204947197029803, 'revenue_per_user_a': 11.737393468737555, 'revenue_per_user_b': 17.115247087183608, 'revenue_lift_percent': 45.81812506132575, 'estimated_roi_percent': 1603.9939999999997}}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e21cf5a7-0b7e-4091-a56f-b149cfffbdc6\", \"conversion_rates.html\", 4567682)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " conversion_rates.html indirildi\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f6db3e77-ddda-407d-aba2-a24d9e9ea564\", \"device_segmentation.html\", 4566919)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " device_segmentation.html indirildi\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7434f9e3-0776-44c0-9724-d992aa79c65a\", \"revenue_distribution.html\", 4584393)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " revenue_distribution.html indirildi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cQ0ct-cN9Hcl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}